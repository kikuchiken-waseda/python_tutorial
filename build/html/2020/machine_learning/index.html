

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="ja" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="ja" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>機械学習の基礎 &mdash; k-lab-seminar 2019 ドキュメント</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/translations.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="検索" href="../../search.html" />
    <link rel="next" title="WEB API 入門: 応用課題" href="../python/web_api.html" />
    <link rel="prev" title="おわりに" href="../introduction_to_nlp/conclusion.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> k-lab-seminar
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">2019 年 度資料</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../2019/env/index.html">開発環境</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../2019/python/index.html">はじめての Python</a></li>
</ul>
<p class="caption"><span class="caption-text">2020 年 度資料</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../python/computer_science_basics.html">計算機科学基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linearRegression/index.html">回帰分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction_to_nlp/index.html">自然言語処理入門</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">機械学習の基礎</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id3">1 : 機械学習とは何か</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">1.1 : 実用的な判断とは</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">1.2 : 記述が難しい規則性とは</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id6">2 : どんな種類があるのか</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id7">2.1 : 機械学習の段階</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id8">2.1.1 : 特徴量エンジニアリング/特徴量抽出</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9">2.1.2 : モデリング</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id10">2.2 : 手法の種類</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id11">2.2.1 : 教師あり学習</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id12">2.2.2 : 教師なし学習</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id13">2.2.3 : 強化学習</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id14">3 : どうやって学習するのか</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id15">3.1 : 回帰タスク</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id16">3-2: クラス分類タスク</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id17">4 : 目的は達成できたのか</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id18">4-1 : 評価指標</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id19">4-2 : データ分割/過学習</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id20">実習 : 実際に手を動かしてみよう</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../python/web_api.html">WEB API 入門: 応用課題</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/job_queuing.html">JOB QUEING 入門</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/statistics/index.html">ベイズ統計</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">k-lab-seminar</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>機械学習の基礎</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/2020/machine_learning/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1><a class="toc-backref" href="#id26">機械学習の基礎</a><a class="headerlink" href="#id1" title="このヘッドラインへのパーマリンク">¶</a></h1>
<div class="contents topic" id="id2">
<p class="topic-title">目次</p>
<ul class="simple">
<li><p><a class="reference internal" href="#id1" id="id26">機械学習の基礎</a></p>
<ul>
<li><p><a class="reference internal" href="#id3" id="id27">1 : 機械学習とは何か</a></p></li>
<li><p><a class="reference internal" href="#id6" id="id28">2 : どんな種類があるのか</a></p></li>
<li><p><a class="reference internal" href="#id14" id="id29">3 : どうやって学習するのか</a></p></li>
<li><p><a class="reference internal" href="#id17" id="id30">4 : 目的は達成できたのか</a></p></li>
<li><p><a class="reference internal" href="#id20" id="id31">実習 : 実際に手を動かしてみよう</a></p></li>
</ul>
</li>
</ul>
</div>
<p>この資料及び実習はGoogle Colab (<a class="reference external" href="https://colab.research.google.com/?hl=ja">https://colab.research.google.com/?hl=ja</a> ) での実行を想定しています.
Google ColabはノートブックというPython REPLを便利にした環境で,
よく使われるモジュールが事前にインストールされています.
URLにアクセスし, Googleアカウントでログインするとノートブック作成画面(オレンジ色)が出ます.
作成画面右下の「ノートブックを新規作成」ボタンを押すことで, ノートブックが作成されます.
作成されたノートブックには文字を書くセルというスペースがあり,
そこにコードを書いてShift+Enterキーを押すとコードが実行されるというものです.</p>
<div class="section" id="id3">
<h2><a class="toc-backref" href="#id27">1 : 機械学習とは何か</a><a class="headerlink" href="#id3" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>機械学習とは一体どのようなものを言うのでしょうか.
これについてある本では以下のような一言でまとめています.</p>
<div class="line-block">
<div class="line">機械学習とは、データから知識を引き出すことである。</div>
<div class="line"><br /></div>
<div class="line">- Andreas C. Müller, Sarah Guido: &quot;Pythonではじめる機械学習&quot; 中田秀基(訳), 株式会社オライリー・ジャパン, 東京, 2018.</div>
</div>
<p>あまりにも簡潔にまとまり過ぎているので, 少し情報を足してみます.
概ね以下のようにまとめられるのでは無いでしょうか.</p>
<ol class="arabic simple">
<li><p>世の中にはたくさんのデータが存在している.</p></li>
<li><p>こういったデータ/データ間には記述が難しい規則性(= 知識)を含む物がある.</p></li>
<li><p>記述が難しい規則性をデータから引き出すことで, 実用的な判断を行う.</p></li>
</ol>
<p>ここで,  <strong>実用的な判断</strong> とか <strong>記述が難しい規則性</strong> とか, 何だか回りくどい表現を使ってしまいました.
以下に簡単に意味を定義しておきましょう.</p>
<div class="section" id="id4">
<h3>1.1 : 実用的な判断とは<a class="headerlink" href="#id4" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>ここでの実用的な判断とは, ある目的を達成するために効率的に自動化された判断だと考えます.
例えば以下に示すようなものが考えられるでしょう.</p>
<a class="reference internal image-reference" href="../../_images/machine_learning_purpose.png"><img alt="../../_images/machine_learning_purpose.png" src="../../_images/machine_learning_purpose.png" style="width: 419.20000000000005px; height: 232.0px;" /></a>
<ul class="simple">
<li><p>コンピュータ操作が人の言葉でできると人間フレンドリーなので,
コンピュータに人の言葉を理解させる</p></li>
<li><p>工場の生産ラインで検品にかかるコストを減らしたいので,
写真から製品の異常を見つける</p></li>
<li><p>化合物の薬効確認には特殊な機械/実験と時間を要するので,
計算を近似することでシミュレーションする</p></li>
<li><p>人が情報を処理する仕組みが分かってきたので,
コンピュータに再現して人に近い判断が可能か試す</p></li>
</ul>
<p>随分わざとらしくカンマで区切っていますが,
文章のカンマ以前の内容がここで言う目的です.
一方でカンマ以降の内容がここで言う効率的に自動化された判断と言うことになります.</p>
</div>
<div class="section" id="id5">
<h3>1.2 : 記述が難しい規則性とは<a class="headerlink" href="#id5" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>記述が難しいとはどう言うことでしょうか.
例えば, 上記の目標を達成するのに必要な規則を考えてみましょう.
試しに「コンピュータに人の言葉を理解させる」と言う方向で, 人と話すシステムを書いてみます.</p>
<div class="literal-block-wrapper docutils container" id="id21">
<div class="code-block-caption"><span class="caption-text">dora.py</span><a class="headerlink" href="#id21" title="このコードへのパーマリンク">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">dora</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>

    <span class="k">if</span> <span class="s2">&quot;初めまして&quot;</span> <span class="o">==</span> <span class="n">text</span><span class="p">:</span>
        <span class="n">reply</span> <span class="o">=</span> <span class="s2">&quot;僕ドラです。&quot;</span>

    <span class="k">elif</span> <span class="s2">&quot;こんにちは&quot;</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="n">reply</span> <span class="o">=</span> <span class="s2">&quot;こんにちは。&quot;</span>

    <span class="k">elif</span> <span class="s2">&quot;こんばんは&quot;</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="n">options</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;こんばんは。&quot;</span><span class="p">,</span> <span class="s2">&quot;こんばんわ。&quot;</span><span class="p">,</span> <span class="s2">&quot;今晩は。&quot;</span><span class="p">]</span>
        <span class="n">reply</span> <span class="o">=</span>  <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">reply</span> <span class="o">=</span>  <span class="s2">&quot;すみません、よくわかりません。&quot;</span>

    <span class="k">return</span> <span class="n">reply</span>

<span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;青色たぬき!&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dora</span><span class="p">(</span><span class="n">input_text</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>適切な記述 (人手によるルール作成) を行うためには,
想定し得る入力文や概念の数だけ応答を作成しなければならないですね.
こんなif-else文を書き連ねるのは非常につらいです.
しかし, これでも文字列を使っているだけまだ人間フレンドリーな方で,
データが小数値を取ったらもっと悲惨なことになります.
「室内温度が29.989度以上かつ湿度が80.23%以上かつ室内の人の服の重さ平均が256.17g以上の時に冷房を入れる」
のような制御の判断基準を人手で吟味しながら調整する作業を考えて貰えれば分かるでしょうか.</p>
<p>つまり, 「記述が難しい」とは, このように判断基準が複雑になりすぎることだと言えます.</p>
<p>定義の話が長くなってしまいましたが,
以上が機械学習が以下のようなものを指すと言うことの説明でした.</p>
<ol class="arabic simple">
<li><p>世の中にはたくさんのデータが存在している.</p></li>
<li><p>こういったデータ/データ間には記述が難しい規則性(= 知識)を含む物がある.</p></li>
<li><p>記述が難しい規則性をデータから引き出すことで, 実用的な判断を行う.</p></li>
</ol>
</div>
</div>
<div class="section" id="id6">
<h2><a class="toc-backref" href="#id28">2 : どんな種類があるのか</a><a class="headerlink" href="#id6" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>機械学習にはどのような種類があるでしょうか?
この章では, 機械学習の段階的な分類と手法的な分類を確認していきます.</p>
<div class="section" id="id7">
<h3>2.1 : 機械学習の段階<a class="headerlink" href="#id7" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>機械学習の手法的な種類を考える前に、機械学習における以下の2段階についてまとめます.</p>
<ol class="arabic simple">
<li><p>特徴量エンジニアリング/特徴量抽出</p></li>
<li><p>モデリング</p></li>
</ol>
<div class="section" id="id8">
<h4>2.1.1 : 特徴量エンジニアリング/特徴量抽出<a class="headerlink" href="#id8" title="このヘッドラインへのパーマリンク">¶</a></h4>
<p>一言で言ってしまうと, 判断を行うためにデータについて良い表現を得ることです.</p>
<p>例えばリンゴとバナナの仕分けをする時に, どういう情報に着目するのが良いでしょうか?
重さの違いで分けるというのは, サイズによる重さのバラつきもあり, あまり適切では無さそうです.
写真を取って色で分ければ(青リンゴなどの例外をのぞいて), 綺麗に分けられそうです.
つまり、リンゴとバナナというデータを分ける場合には, 色の情報が「判断のための良い表現である」と言えます.</p>
<a class="reference internal image-reference" href="../../_images/fruits.png"><img alt="../../_images/fruits.png" src="../../_images/fruits.png" style="width: 344.8px; height: 192.0px;" /></a>
<p>あるいは, もっと数値的に, データのスケールを統一する場合などもあります.
0から255までを取るデータと-10から10までを取るデータをそのままのスケールで判断に利用するよりも,
どちらのデータも-1から1までで収まるデータに変換をした方がコンピュータ的には判断がしやすいのです.</p>
<a class="reference internal image-reference" href="../../_images/feature_engineering.png"><img alt="../../_images/feature_engineering.png" src="../../_images/feature_engineering.png" style="width: 513.0px; height: 319.0px;" /></a>
<p>データスケールの統一をpythonで行う方法はいくつか考えられますが, 一つは以下のようなものです.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># データや計算を扱うモジュールのロード</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># データの初期化: 9つ特徴量(説明変数)のデータを3つ含む行列</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
  <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
   <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
   <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]</span>
<span class="p">)</span>

<span class="c1"># データのスケールを統一するクラスのロードと宣言</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="c1"># スケーリング</span>
<span class="n">scaled_x</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>このような良い表現を探す段階を特徴量エンジニアリングとか特徴量抽出とか言います.</p>
<ul class="simple">
<li><p>人が経験や知識を持って良い表現を選択することを特徴量エンジニアリング</p></li>
<li><p>選択すらもコンピュータにやらせることを特徴量抽出</p></li>
</ul>
<p>と呼ぶことが多いようです.</p>
</div>
<div class="section" id="id9">
<h4>2.1.2 : モデリング<a class="headerlink" href="#id9" title="このヘッドラインへのパーマリンク">¶</a></h4>
<p>一言で言ってしまうと, 得た表現を元に判断基準を考えることです.</p>
<p>先ほどのリンゴとバナナの例で言えば, 色情報をRGBの3原色で表した時に,
どの範囲をリンゴとし, どの範囲をバナナとするかをデータから学習する段階になります.</p>
<a class="reference internal image-reference" href="../../_images/modeling.png"><img alt="../../_images/modeling.png" src="../../_images/modeling.png" style="width: 475.20000000000005px; height: 227.20000000000002px;" /></a>
</div>
</div>
<div class="section" id="id10">
<h3>2.2 : 手法の種類<a class="headerlink" href="#id10" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>機械学習は学習時のデータの与え方によって以下の3つに大別されます.</p>
<ul class="simple">
<li><p>教師あり学習</p></li>
<li><p>教師なし学習</p></li>
<li><p>強化学習</p></li>
</ul>
<div class="section" id="id11">
<h4>2.2.1 : 教師あり学習<a class="headerlink" href="#id11" title="このヘッドラインへのパーマリンク">¶</a></h4>
<p>教師あり学習は, 判断するためのデータと正解の判断結果の両方を与えて判断基準を探す学習です.</p>
<ul class="simple">
<li><p>事例1: Aというデータはリンゴと判断するのが正解だった</p></li>
<li><p>事例2: Bというデータはバナナと判断するのが正解だった</p></li>
<li><p>事例3: Cというデータはバナナと判断するのが正解だった</p></li>
</ul>
<p>といった具合に正解となった判断をお手本にして判断基準を決めていく学習です.</p>
<p>これまで「判断」という言葉を使ってきましたが, 教師あり学習ではタスクが大きく二つに分かれます.
一つはこれまで考えてきたようにデータからリンゴとバナナ等のカテゴリーを判断する <strong>クラス分類</strong> タスクです.
もう一つはデータから何かしらの数値を判断する <strong>回帰</strong> タスクです.</p>
</div>
<div class="section" id="id12">
<h4>2.2.2 : 教師なし学習<a class="headerlink" href="#id12" title="このヘッドラインへのパーマリンク">¶</a></h4>
<p>教師なし学習は, データだけを与えて良い表現を獲得する学習です.</p>
<p>コンピュータに取って良い表現を得る為に先ほどのような観察, 先行研究に頼るのも手段のひとつですが,
そのような手がかりがなかった場合にデータの分布から機械的に良い表現を抽出することができます.
例えば、リンゴとバナナの判別においてRGBの3原色の内データの分散を取って見て
G(緑)の分散が大きいと分かれば, 3原色の中でも緑成分に注目するのが良い表現だと言えます.
このようにたくさんの特徴量からより良いデータを探す学習を <strong>次元削減</strong> と言います.
データリテラシーで扱った主成分分析(PCA)等がこれに当たります.</p>
<p>また, ここで「良い表現」は, コンピュータにとっての良い表現ではなく, 人にとって良い表現な場合もあります.
次元削減を行ってデータの分布をうまく表す二次元平面上の表現を得る <strong>可視化</strong> も一つです.
その他にも, データの分布にはどのようなまとまりが存在しそうかを得る「クラスタリング」があります.</p>
<a class="reference internal image-reference" href="../../_images/visualizing.png"><img alt="../../_images/visualizing.png" src="../../_images/visualizing.png" style="width: 511.0px; height: 361.0px;" /></a>
<p>このように, 教師なし学習は教師となる情報を与えられない代わりに,
データ自体から得られる情報を教師代わりに学習を行います.</p>
</div>
<div class="section" id="id13">
<h4>2.2.3 : 強化学習<a class="headerlink" href="#id13" title="このヘッドラインへのパーマリンク">¶</a></h4>
<p>強化学習は, ある環境下において何かしらの行動を取る場合に価値のもっとも大きな行動を判断させる学習です.</p>
<p>例えば囲碁等のボードゲーム(環境)において価値が最大となるのはゲームに勝つ結果を伴う行動です.
盤面というデータが与えられた時に適切な手を判断するという点では教師あり学習に近いですが,
教師あり学習は一つ一つの盤面に正解の行動がある一方,
強化学習では正解はあくまでもゲームでの最終的な勝ちとなります.
対話システム, ロボット制御, 経営戦略分析等幅広く用いられる手法ですが, 少し状況が特殊なため今回は割愛します.</p>
</div>
</div>
</div>
<div class="section" id="id14">
<h2><a class="toc-backref" href="#id29">3 : どうやって学習するのか</a><a class="headerlink" href="#id14" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>この章では, ここまで説明してきた機械学習モデル(回帰, クラス分類)の学習について雰囲気を掴みましょう.
視覚的な解説をするために実装コードが少し複雑になっています. 必ずしも読める必要はありません.</p>
<div class="section" id="id15">
<h3>3.1 : 回帰タスク<a class="headerlink" href="#id15" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>回帰タスクは, データから数値を予測するタスクでした.
つまり, データをx, 数値をyとした場合, <span class="math notranslate nohighlight">\(y=Wx+b\)</span> の関係で表すわけです.
回帰タスクにおける学習とは, xとyとのペアから, 判別するのに適切なWとbを探す作業になります.
これは, <span class="math notranslate nohighlight">\(Wx+b\)</span> と <span class="math notranslate nohighlight">\(y\)</span> との差が最も小さくなる,
つまり <span class="math notranslate nohighlight">\(E(x, y) = (Wx+b-y)^2\)</span> という関数の出力を最適化する作業と置くことができます.
これを <strong>最小二乗法</strong> と言います.
関数の出力は関数を微分することで最小化できます.
これを <strong>勾配降下法</strong> と言います.</p>
<p>以下では, 回帰の最適化を可視化してみます.
まずは可視化しやすいような簡単なデータを作成します.</p>
<div class="literal-block-wrapper docutils container" id="id22">
<div class="code-block-caption"><span class="caption-text">init_toy_data_regression.py</span><a class="headerlink" href="#id22" title="このコードへのパーマリンク">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">true_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;データの裏に想定したい関数</span>
<span class="sd">  y = 1.2x + 0.1 とする.&quot;&quot;&quot;</span>
  <span class="n">y</span> <span class="o">=</span> <span class="mf">1.2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.1</span>
  <span class="k">return</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">init_toy_data</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;擬似的なデータを作る.</span>
<span class="sd">  学習データのため, yの値に少しだけノイズを乗せる.&quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">true_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">noise</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">noise</span>
  <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">init_toy_data</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">true_func</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Explanatory&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Objective&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;toy_data_regression.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<a class="reference internal image-reference" href="../../_images/toy_data_regression.png"><img alt="../../_images/toy_data_regression.png" src="../../_images/toy_data_regression.png" style="width: 388.8px; height: 259.2px;" /></a>
<p>上のようなデータセットを作成しました.
青い点は一つ一つがデータであり, 黄緑色の線は裏に想定している関数(機械学習で見つける法則性)です.</p>
<p>では, 最適化をしていきましょう.</p>
<div class="literal-block-wrapper docutils container" id="id23">
<div class="code-block-caption"><span class="caption-text">fit_linear_regression.py</span><a class="headerlink" href="#id23" title="このコードへのパーマリンク">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">jit</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="k">as</span> <span class="nn">animation</span>
<span class="kn">from</span> <span class="nn">init_toy_data</span> <span class="kn">import</span> <span class="n">true_func</span><span class="p">,</span> <span class="n">init_toy_data</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">init_toy_data</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># 最適化の定数と回帰モデルのパラメータ</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">data_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="k">if</span> <span class="n">data_size</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
  <span class="n">iteration</span> <span class="o">=</span> <span class="n">data_size</span> <span class="o">//</span> <span class="n">batch_size</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">iteration</span> <span class="o">=</span> <span class="n">data_size</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.7</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;W&quot;</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">])}</span>
<span class="n">params_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">params</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;回帰モデルの予測関数&quot;&quot;&quot;</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;W&quot;</span><span class="p">])</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">calc_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;最適化をすべき損失関数&quot;&quot;&quot;</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">diff</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">diff</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">loss</span>

<span class="c1"># 損失関数を自動的に微分する</span>
<span class="n">grad_func</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">calc_loss</span><span class="p">))</span>

<span class="c1"># 最適化処理</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">i</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">batch_size</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">bx</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
    <span class="n">by</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">calc_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">bx</span><span class="p">,</span> <span class="n">by</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">grad_func</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">bx</span><span class="p">,</span> <span class="n">by</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
      <span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

  <span class="n">params_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>

<span class="c1"># gif画像の描画</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">update_func</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">true_func</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">predict</span><span class="p">(</span><span class="n">params_history</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Explanatory&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Objective&#39;</span><span class="p">)</span>

<span class="n">ani</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update_func</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ani</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;fit_linear_regression.gif&quot;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s2">&quot;imagemagick&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<a class="reference internal image-reference" href="../../_images/fit_linear_regression.gif"><img alt="../../_images/fit_linear_regression.gif" src="../../_images/fit_linear_regression.gif" style="width: 388.8px; height: 259.2px;" /></a>
<p>このように, 青色で書かれた各データ点と回帰直線との距離が最小になるように最適化がされていきます.
ここまで色々とコードを書きましたが, 実際に学習をする時にはここまで面倒臭いことはしません.
実際には,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># データの初期化: yには乱数でノイズを乗せている</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.2</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="mf">0.1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="mf">0.05</span>

<span class="c1"># モジュールのロード</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># 回帰モデルの呼び出し</span>
<span class="n">regressor</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># 回帰モデルの最適化(xは説明変数, yは目的変数です)</span>
<span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># 回帰モデルの推論</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># モデルの係数(Wx+bのWとb)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
</div>
<p>とやるだけで済んでしまいます.</p>
</div>
<div class="section" id="id16">
<h3>3-2: クラス分類タスク<a class="headerlink" href="#id16" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>クラス分類タスクは, データからデータの属するカテゴリーを予測するタスクでした.
より正確にはカテゴリーそのものを返すよりも, カテゴリーに属するかどうかの確率を求めるタスクです.
データxが起きた時に, それがあるカテゴリーに属する確率は <span class="math notranslate nohighlight">\(p(y|x)\)</span> として表すことができます.
このような考え方を条件付き確率と言います.
後はデータがカテゴリーに属する場合は <span class="math notranslate nohighlight">\(p(y|x)\)</span> を大きくし, 属さない場合は小さくして最適化を行います.</p>
<p>回帰タスクとの違いは大きく以下の2点になります.</p>
<ul class="simple">
<li><p>回帰タスクでは予測数値をそのまま出力するが, クラス分類では1から0までの確率を出力する.</p></li>
<li><p>正解データと予測の差を求める場合に, 回帰タスクでは <strong>最小二乗法</strong> という考え方を用いたが,
クラス分類では <strong>最尤法</strong> と呼ばれる考え方を用いる.</p></li>
</ul>
<p>その他 <strong>勾配降下法</strong> を用いて最適化を行う点などは基本的に同じとなります.</p>
<p>まずは回帰と同様, 簡単なデータを作成しましょう.</p>
<div class="literal-block-wrapper docutils container" id="id24">
<div class="code-block-caption"><span class="caption-text">init_toy_data_classification.py</span><a class="headerlink" href="#id24" title="このコードへのパーマリンク">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">5</span><span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">5</span><span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Score 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Score 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;toy_data_classification.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<a class="reference internal image-reference" href="../../_images/toy_data_classification.png"><img alt="../../_images/toy_data_classification.png" src="../../_images/toy_data_classification.png" style="width: 388.8px; height: 259.2px;" /></a>
<p>このように, 色の違い(=カテゴリーの違い)によって隔てられたデータを作りました.
それでは, このデータに対してクラス分類の最適化が行われる流れを可視化してみましょう.</p>
<div class="literal-block-wrapper docutils container" id="id25">
<div class="code-block-caption"><span class="caption-text">fit_linear_classification.py</span><a class="headerlink" href="#id25" title="このコードへのパーマリンク">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 最適化の定数と回帰モデルのパラメータ</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">data_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">if</span> <span class="n">data_size</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
  <span class="n">iteration</span> <span class="o">=</span> <span class="n">data_size</span> <span class="o">//</span> <span class="n">batch_size</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">iteration</span> <span class="o">=</span> <span class="n">data_size</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">2.</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;W&quot;</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">])}</span>
<span class="n">params_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">params</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;シグモイド関数</span>
<span class="sd">  モデルの出力を確率にする&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;クラス分類モデルの予測関数&quot;&quot;&quot;</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;W&quot;</span><span class="p">])</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">calc_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;最適化をすべき損失関数&quot;&quot;&quot;</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">true_diff</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">*</span> <span class="n">y_true</span>
  <span class="n">false_diff</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_true</span><span class="p">)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">true_diff</span> <span class="o">+</span> <span class="n">false_diff</span>
  <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="c1"># 損失関数を自動的に微分する関数</span>
<span class="n">grad_func</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">calc_loss</span><span class="p">))</span>

<span class="c1"># 最適化処理</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">i</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">batch_size</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">bx</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
    <span class="n">by</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">calc_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">bx</span><span class="p">,</span> <span class="n">by</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">grad_func</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">bx</span><span class="p">,</span> <span class="n">by</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
      <span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

  <span class="n">params_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>

<span class="c1"># gif画像の描画</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">x_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="mi">100</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">update_func</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

  <span class="n">params</span> <span class="o">=</span> <span class="n">params_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">y_label</span> <span class="o">=</span> <span class="o">-</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x_label</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">5</span><span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">5</span><span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_label</span><span class="p">,</span> <span class="n">y_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Score 1&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Score 2&#39;</span><span class="p">)</span>

<span class="n">ani</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update_func</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">params_history</span><span class="p">),</span> <span class="n">interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ani</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;fit_linear_classification.gif&quot;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s2">&quot;imagemagick&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<a class="reference internal image-reference" href="../../_images/fit_linear_classification.gif"><img alt="../../_images/fit_linear_classification.gif" src="../../_images/fit_linear_classification.gif" style="width: 388.8px; height: 259.2px;" /></a>
<p>以上のコードも, 回帰の時と同様数行のコードで表せます.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># データの初期化</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

<span class="c1"># モジュールのロード</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># クラス分類モデルの読み込み</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="c1"># クラス分類モデルの学習</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># クラス分類モデルの推論</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># モデルの係数(Wx+bのWとb)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id17">
<h2><a class="toc-backref" href="#id30">4 : 目的は達成できたのか</a><a class="headerlink" href="#id17" title="このヘッドラインへのパーマリンク">¶</a></h2>
<div class="section" id="id18">
<h3>4-1 : 評価指標<a class="headerlink" href="#id18" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>機械学習で重要なことは, 実用に耐え得る判断ができるかどうかです.
では, 実用に耐え得るかどうかはどのようにして評価するのでしょうか?
これまで見てきたように, 基本的にデータから経験的に知識を獲得する機械学習は,
判断の根拠などが曖昧になることも少なくありません.
そこで, 評価においても学習同様データを利用した評価が考えられます.</p>
<p>回帰タスクであれば, 学習同様に予測値と正解値との誤差を図ることで,
予測がどの程度正確であるか測ることができます.
ある予測値に対して, 平均的にどの程度の誤差が発生するかが分かれば解釈しやすいでしょう.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">])</span>

<span class="c1"># 平均的にどの程度誤差が発生するか計算している</span>
<span class="c1"># 標準偏差と平均偏差の違いのように(外れ値に頑健にするか否か),</span>
<span class="c1"># 距離を差の二乗とするか, 差の絶対値とするかでsquaredとabsoluteが違う</span>

<span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
<p>一方で, クラス分類タスクの場合はどうでしょうか?
どれだけ間違えずにクラスを予測できるかで測れるのではないでしょうか.
ただし, クラス分類の間違え方には種類があります.</p>
<a class="reference internal image-reference" href="../../_images/confusion_matrix.png"><img alt="../../_images/confusion_matrix.png" src="../../_images/confusion_matrix.png" style="width: 397.6px; height: 170.4px;" /></a>
<p>このような表を混合行列(Confusion Matrix)と呼びます.
これらの間違いは, 適用先の分野などによって重要性が異なります.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Accuracy = \frac {TP+TN} {TP+FN+FP+TN}\\Recall = \frac {TP} {TP+FN}\\Precision = \frac {TP} {TP+FP}\\F1 Score = \frac {Recall*Precision} {Recall+Precision}\end{aligned}\end{align} \]</div>
<p>最も一般的なのはAccuracyですが, どの間違い/正解に重きをおくかによって様々な評価方法があります.
Recallは「本来Positiveと判断すべきものの内, Positiveと判断できたものの率」を表し,
Precisionは「Positiveと判断してしまったものの内, Positiveと判断できたものの率」を表します.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># 混合行列の取得</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># accuracy, recall, precisionなどの結果要約</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="id19">
<h3>4-2 : データ分割/過学習<a class="headerlink" href="#id19" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>機械学習モデルの評価時には, もう一点データ分割のことを考えなければいけません.
学習に使ったデータは, 当然それに合わせて最適化されているので精度が高めに出ます.
そのため, 学習に使う(Train)データと評価に使う(Test)データを分けなければリークとなってしまいます.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>

<span class="c1"># データをシャッフルしてテストサイズが全体の10%となるように分ける</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<p>上記の例は単純な分割ですが, より厳密な評価を行うためには,
データセットの分け方までこだわる必要があります.</p>
<a class="reference internal image-reference" href="../../_images/evaluate.png"><img alt="../../_images/evaluate.png" src="../../_images/evaluate.png" style="width: 425.6px; height: 202.4px;" /></a>
<p>また, 機械学習モデルはモデルの学習に関わる色々な値を変更しながら精度の向上を目指します.
最終的には一番良いモデルを選択するわけですが,
選択するための評価をする時に, 検証(Validation)用データセットを新たに分割することが基本です.
モデル選択は学習の一部のため評価が必要でも, Testデータに手を付けるわけにはいかないわけです.</p>
</div>
</div>
<div class="section" id="id20">
<h2><a class="toc-backref" href="#id31">実習 : 実際に手を動かしてみよう</a><a class="headerlink" href="#id20" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>Google Colab (<a class="reference external" href="https://colab.research.google.com/?hl=ja">https://colab.research.google.com/?hl=ja</a> ) で実際にcsvデータを使ってクラス分類をしてみましょう.</p>
<p>データの読み込みにはpandasというモジュールを使います</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># データフレームという物にデータを入れています.</span>
<span class="c1"># Rでデータを扱う時の表にまとまったデータ構造に近いです.</span>
<span class="c1"># `df`の部分までをColabの一つのセルに入れて実行してみましょう, 綺麗な表が出るはずです.</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./twitter_dataset.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>

<span class="c1"># describeメソッドでデータの基本統計量が手軽に出ます.</span>

<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>

<span class="c1"># データフレームは列名を指定するとその列のデータが全部取れます.</span>
<span class="c1"># 取る列に条件をつけることもできます.</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;personality&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;personality&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;personality&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]))</span>

<span class="c1"># データフレームから目的変数と説明変数とを分けます.</span>
<span class="c1"># valuesを取得すると, 先ほどまででお馴染みのNumpy配列に変換されます.</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">!=</span><span class="s2">&quot;personality&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;personality&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../python/web_api.html" class="btn btn-neutral float-right" title="WEB API 入門: 応用課題" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../introduction_to_nlp/conclusion.html" class="btn btn-neutral float-left" title="おわりに" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Takuya Asai

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>